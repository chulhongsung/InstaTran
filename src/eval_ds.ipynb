{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.abspath(''))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('')))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('') + '/src'))\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from layers import *\n",
    "from models import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from ing_theme_matplotlib import mpl_style\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "mpl_style(dark=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ding = STALSTM(48, 16, 12, 5)\n",
    "\n",
    "adj = torch.tensor([[1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                    [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "        ).float()\n",
    "\n",
    "norm_adj = adj/adj.sum(dim=-1).unsqueeze(-1)\n",
    "deng = HSDSTM(adj=norm_adj,                  \n",
    "                input_size=16,\n",
    "                seq_len=48,\n",
    "                num_channels=[16, 16],\n",
    "                node_dim=1,\n",
    "                dropout=0.1,\n",
    "                num_levels=3,\n",
    "                tau=12,\n",
    "                num_quantiles=5)\n",
    "\n",
    "\n",
    "deepar = DeepAR(\n",
    "        d_input=16, \n",
    "        d_embedding=3, \n",
    "        n_embedding=[16, 32, 24], \n",
    "        d_model=30, \n",
    "        num_targets=1, \n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "mqrnn = MQRnn(\n",
    "        d_input=16,\n",
    "        d_embedding=1,\n",
    "        n_embedding=[16, 32, 24],\n",
    "        d_model=5,\n",
    "        tau=12,\n",
    "        num_targets=1,\n",
    "        num_quantiles=5,\n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "quanilte_levels = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "tft = TemporalFusionTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=quanilte_levels,\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "sps = torch.tensor([ [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "                ).float()\n",
    "\n",
    "instatran = InstaTran(\n",
    "    d_model=20,\n",
    "    d_embedding=3,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=sps,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=quanilte_levels,\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2017\"\n",
    "deepar.load_state_dict(torch.load('../assets/ds/ds_DeepAR_{}_best.pth'.format(year), map_location='cpu'))\n",
    "mqrnn.load_state_dict(torch.load('../assets/ds/ds_MQRnn_{}_best.pth'.format(year), map_location='cpu'))\n",
    "tft.load_state_dict(torch.load('../assets/ds/ds_TFT_{}_best.pth'.format(year), map_location='cpu'))\n",
    "ding.load_state_dict(torch.load('../assets/ds/ds_STALSTM_{}_best.pth'.format(year), map_location='cpu'))\n",
    "deng.load_state_dict(torch.load('../assets/ds/ds_HSDSTM_{}_best.pth'.format(year), map_location='cpu'))\n",
    "instatran.load_state_dict(torch.load('../assets/ds/ds_InstaTran_{}_best.pth'.format(year), map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in [\"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"]:\n",
    "df_test_total = pd.read_csv(\"../data/df_test_total_ds_{}.csv\".format(year))\n",
    "df_merged = pd.read_csv(\"../data/df_merged_ds_{}.csv\".format(year))\n",
    "\n",
    "test_input, eval_label = generate_ts_data_for_deng(df_test_total, df_merged)\n",
    "deng.eval()\n",
    "eval_label = torch.tensor(eval_label)\n",
    "deng_output = deng(torch.tensor(test_input))\n",
    "\n",
    "print(torch.maximum(0.9 * (eval_label.squeeze() - deng_output[..., 4].squeeze()), (1-0.9)*(deng_output[..., 4].squeeze() -eval_label.squeeze() )).mean())\n",
    "print(np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 4].squeeze().detach().cpu().numpy()))\n",
    "print(0.9 - np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 4].squeeze().detach().cpu().numpy()))\n",
    "\n",
    "print(torch.maximum(0.7 * (eval_label.squeeze() - deng_output[..., 3].squeeze()), (1-0.7)*(deng_output[..., 3].squeeze() -eval_label.squeeze() )).mean())\n",
    "print(np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 3].squeeze().detach().cpu().numpy()))\n",
    "print(0.7 - np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 3].squeeze().detach().cpu().numpy()))\n",
    "\n",
    "print(torch.maximum(0.5 * (eval_label.squeeze() - deng_output[..., 2].squeeze()), (1-0.5)*(deng_output[..., 2].squeeze() -eval_label.squeeze() )).mean())\n",
    "print(np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 2].squeeze().detach().cpu().numpy()))\n",
    "print(0.5 - np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 2].squeeze().detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft.load_state_dict(torch.load('../assets/ds/ds_TFT_{}_best.pth'.format(year), map_location='cpu'))\n",
    "\n",
    "test_conti, test_cate, test_future, eval_label = generate_ts_data(df_test_total, df_merged, input_seq_len=48, tau=12)\n",
    "tft.eval()\n",
    "\n",
    "confe_output = tft.confe(torch.FloatTensor(test_conti)) # (batch_size, seq_len, num_cv, d_embedding)\n",
    "catfe_output = tft.catfe(torch.LongTensor(test_cate))  # (batch_size, seq_len, num_cate, d_embedding)\n",
    "obs_feature = torch.cat([confe_output, catfe_output], axis=-2)  # (batch_size, seq_len, num_cv + num_cate, d_embedding)\n",
    "x1, tft_vsn_output  = tft.vsn1(obs_feature) # (batch_size, seq_len, d_model)\n",
    "\n",
    "tft_output = tft(torch.FloatTensor(test_conti), torch.LongTensor(test_cate), torch.LongTensor(test_future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.load_state_dict(torch.load('../assets/ds/ds_InstaTran_{}_best.pth'.format(year), map_location='cpu'))\n",
    "instatran.eval()\n",
    "stt_output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2 = instatran(torch.FloatTensor(test_conti), torch.LongTensor(test_cate), torch.LongTensor(test_future))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idx = 1\n",
    "f, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True)\n",
    "\n",
    "sns.lineplot(test_conti[::48, :, feature_idx].squeeze().reshape(-1)[30:], label=r\"Observation of $P_2$\", ax=ax1).set(xlabel=\"Time points\")\n",
    "sns.lineplot(test_conti[::48, :, feature_idx].squeeze().reshape(-1)[30:], label=r\"Observation of $P_2$\", ax=ax2)\n",
    "sns.lineplot(fi1.detach().cpu()[::48, :, feature_idx, 0].reshape(-1)[30:], linestyle='--', label=r\"Importance of $P_2$ (InstaTran)\", ax=ax2)\n",
    "sns.lineplot(tft_vsn_output.detach().cpu()[::48, :, feature_idx, 0].reshape(-1)[30:], linestyle=':', label=r\"Importance of $P_2$ (TFT)\", ax=ax2)\n",
    "\n",
    "ax1.set_ylim(0.5, 3)\n",
    "ax2.set_ylim(0, 0.2)\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "\n",
    "ax1.set_ylabel(\"\")\n",
    "ax2.set_ylabel(\"\")\n",
    "ax2.set_xlabel(\"Time points\")\n",
    "\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "ax1.get_legend().remove()\n",
    "ax2.get_legend().remove()\n",
    "\n",
    "d = .7    \n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=15, linestyle=\"none\", color='k', clip_on=False)\n",
    "\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "ax1.set_yticks([0.5, 1.0, 2.0, 3.0])\n",
    "ax1.set_yticklabels(['0.5', '1.0', '2.0', '3.0'], fontsize = 12)\n",
    "\n",
    "ax2.set_yticks([0.0, 0.1, 0.2])\n",
    "ax2.set_yticklabels(['0.0', '0.1', '0.2'], fontsize = 12)\n",
    "\n",
    "ax2.set_xticks([100 * i + 2 for i in range(15)])\n",
    "ax2.set_xticklabels([str(100 * i) for i in range(15)] ,fontsize = 10)\n",
    "ax2.xaxis.grid()\n",
    "\n",
    "ax1.set_xlim(0, 402)\n",
    "ax2.set_xlim(0, 402)\n",
    "h,l = ax2.get_legend_handles_labels()\n",
    "ax1.legend(handles=h, fontsize=\"12\", loc='upper right', ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          \n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     \n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)  \n",
    "plt.rc('xtick', labelsize=BIGGER_SIZE)   \n",
    "plt.rc('ytick', labelsize=BIGGER_SIZE)   \n",
    "plt.rc('legend', fontsize=BIGGER_SIZE)  \n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  \n",
    "\n",
    "B, tau, num_targets, quantiles = stt_output.shape\n",
    "\n",
    "true = eval_label\n",
    "\n",
    "if type(stt_output) == torch.Tensor:    \n",
    "    preds = stt_output.detach().cpu().numpy()\n",
    "\n",
    "preds_ = preds[::tau, ...].reshape(-1, num_targets, quantiles)\n",
    "true_ = true[::tau, ...].reshape(-1, num_targets)\n",
    "instatran_results = preds_[:, 0, :]\n",
    "\n",
    "df_instatran_results = pd.DataFrame({\"10%\": instatran_results[:, 0],\n",
    "                            \"90%\": instatran_results[:, 4],\n",
    "                            \"Target\": true_[:, 0]}).reset_index().melt(id_vars=['index'])\n",
    "\n",
    "palette = {\n",
    "    'Target': 'white' if False else 'black'\n",
    "}\n",
    "\n",
    "forecasting_position = [tau * x for x in range(B // tau + 1)]\n",
    "\n",
    "B, tau, num_targets, quantiles = tft_output.shape\n",
    "\n",
    "true = eval_label\n",
    "\n",
    "if type(tft_output) == torch.Tensor:    \n",
    "    preds2 = tft_output.detach().cpu().numpy()\n",
    "\n",
    "preds2_ = preds2[::tau, ...].reshape(-1, num_targets, quantiles)\n",
    "tft_result = preds2_[:, 0, :]\n",
    "true_.shape[0]\n",
    "df_tft_result = pd.DataFrame({\"10%\": tft_result[:, 0],\n",
    "                            \"90%\": tft_result[:, 4],\n",
    "                            \"Target\": tft_result[:, 0]}).reset_index().melt(id_vars=['index'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))   \n",
    "ax1 = sns.lineplot(x='index', y='value', hue='variable', data=df_instatran_results.loc[df_instatran_results['variable'] == 'Target',], palette=palette)\n",
    "conf = ax.fill_between(np.arange(preds_.shape[0]), df_instatran_results.loc[df_instatran_results['variable'] == '10%', 'value'], df_instatran_results.loc[df_instatran_results['variable'] == '90%', 'value'], color='blue', alpha=0.3, label=r'80% interval (InstaTran )')\n",
    "ax1.set(xlim=(0, true_.shape[0]), ylabel='Water Level/1000')\n",
    "ax1.set_xlabel(\"Time points\", fontsize=20)\n",
    "# ax2 = sns.lineplot(x='index', y='value', hue='variable', data=df_tft_result.loc[df_tft_result['variable'] == 'Target',], palette=palette)\n",
    "conf = ax.fill_between(np.arange(preds_.shape[0]), df_tft_result.loc[df_tft_result['variable'] == '10%', 'value'], df_tft_result.loc[df_tft_result['variable'] == '90%', 'value'], color='purple', alpha=0.3, label=r'80% interval (TFT)')\n",
    "\n",
    "ax1.set_xticks([100 * i -20 for i in range(15)])\n",
    "ax1.set_xticklabels([str(100 * (i - 5)) for i in range(15)] ,fontsize = 14)\n",
    "ax1.set_xlim(480, 780)\n",
    "ax1.set_ylim(0.23, 0.53)\n",
    "ax.legend(loc = 'upper right')    \n",
    "plt.show()\n",
    "\n",
    "ax.legend(loc = 'upper left')    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
