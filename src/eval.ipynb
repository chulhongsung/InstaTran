{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.abspath(''))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('')))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('') + '/src'))\n",
    "\n",
    "from utils import *\n",
    "from layers import *\n",
    "from models import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from ing_theme_matplotlib import mpl_style # pip install ing_theme_matplotlib \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train_total = pd.read_csv(\"../data/df_train_total.csv\")\n",
    "df_test_total = pd.read_csv(\"../data/df_test_total.csv\")\n",
    "df_merged = pd.read_csv(\"../data/df_merged.csv\")\n",
    "df_train_total\n",
    "train_conti_input, train_cate_input, train_future_input, train_label = generate_ts_data(df_train_total, df_merged)\n",
    "test_conti_input, test_cate_input, test_future_input, test_label = generate_ts_data(df_test_total, df_merged)\n",
    "\n",
    "eval_a, eval_b, eval_c, eval_d, eval_e = generate_eval_ts(df_test_total, df_merged, input_seq_len=48, tau=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti = torch.FloatTensor(eval_a)\n",
    "eval_cate = torch.LongTensor(eval_b)\n",
    "eval_future = torch.LongTensor(eval_c)\n",
    "eval_label = torch.FloatTensor(eval_d)\n",
    "eval_past_label = torch.FloatTensor(eval_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft = TemporalFusionTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "                \n",
    "deepar = DeepAR(\n",
    "        d_input=16, \n",
    "        d_embedding=3, \n",
    "        n_embedding=[16, 32, 24], \n",
    "        d_model=30, \n",
    "        num_targets=1, \n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "mqrnn = MQRnn(\n",
    "        d_input=16,\n",
    "        d_embedding=1,\n",
    "        n_embedding=[16, 32, 24],\n",
    "        d_model=5,\n",
    "        tau=12,\n",
    "        num_targets=1,\n",
    "        num_quantiles=5,\n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "mqrnn.load_state_dict(torch.load(\"../assets/MQRnn.pth\", map_location=\"cpu\"))\n",
    "deepar.load_state_dict(torch.load(\"../assets/DeepAR.pth\", map_location='cpu'))\n",
    "tft.load_state_dict(torch.load(\"../assets/TFT.pth\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepar.eval()\n",
    "output_deepar = deepar(eval_conti, eval_cate, eval_future)\n",
    "output_deepar_mu, output_deepar_sigma = output_deepar\n",
    "output_deepar_mu.detach().cpu().numpy()\n",
    "output_deepar_mu.shape\n",
    "deepar_output = gaussian_quantile(output_deepar_mu, output_deepar_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mqrnn.eval()\n",
    "mqrnn_output = mqrnn(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft.eval()\n",
    "tft_output = tft(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(eval_label[150:170], mqrnn_output[150:170], dark=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = torch.tensor([ [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "                ).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran = InstaTran(\n",
    "    d_model=10,\n",
    "    d_embedding=3,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=sps,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran_wo_sps = SpatialTemporalTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=None,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.load_state_dict(torch.load(\"../assets/InstaTran.pth\", map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran_wo_sps.load_state_dict(torch.load(\"../assets/InstaTran_wo_sps.pth\", map_location='cpu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "mpl_style(dark=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti = torch.FloatTensor(eval_a[1500:1650])\n",
    "eval_cate = torch.LongTensor(eval_b[1500:1650])\n",
    "eval_future = torch.LongTensor(eval_c[1500:1650])\n",
    "eval_label = torch.FloatTensor(eval_d[1500:1650])\n",
    "eval_past_label = torch.FloatTensor(eval_e[1500:1650])\n",
    "\n",
    "instatran.eval()\n",
    "output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2 = instatran(eval_conti, eval_cate, eval_future)\n",
    "\n",
    "instatran_wo_sps.eval()\n",
    "output_no_sps, ssa_weight1_no_sps, ssa_weight2_no_sps, tsa_weight_no_sps, dec_weights_no_sps, fi1_no_sps, fi2_no_sps = instatran_wo_sps(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry\n",
    "plt.matshow(ssa_weight2[10, 15, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")\n",
    "\n",
    "plt.matshow(ssa_weight2_no_sps[10, 15, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainy\n",
    "plt.matshow(ssa_weight2[50, 0, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")\n",
    "\n",
    "plt.matshow(ssa_weight2_no_sps[50, 0, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft.eval()\n",
    "confe_output = tft.confe(eval_conti) \n",
    "catfe_output = tft.catfe(eval_cate)  \n",
    "obs_feature = torch.cat([confe_output, catfe_output], axis=-2)  \n",
    "x1, tft_vsn_output  = tft.vsn1(obs_feature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.eval()\n",
    "instatran_output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2  = instatran(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(eval_conti.cpu()[::48, :, 0].squeeze().reshape(-1)[30:], label=r\"Observation of $P_1$\").set(xlabel=\"Time points\")\n",
    "sns.lineplot(fi1.detach().cpu()[::48, :, 0, 0].reshape(-1)[30:], linestyle='--', label=r\"Importance of $P_1$ (InstaTran)\")\n",
    "# sns.lineplot(fi1.detach().cpu()[::48, :, 11, 0].reshape(-1)[30:], label=\"WL(JS)\")\n",
    "sns.lineplot(tft_vsn_output.detach().cpu()[::48, :, 0, 0].reshape(-1)[30:], linestyle=':', label=r\"Importance of $P_1$ (TFT)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idx = 8\n",
    "importance_mat = np.zeros((150, 197))\n",
    "for i in range(150):\n",
    "    importance_mat[i, i:i+48] = fi1.detach().cpu()[i, :, feature_idx, 0]\n",
    "\n",
    "\n",
    "tft_importance_mat = np.zeros((150, 197))\n",
    "for i in range(150):\n",
    "    tft_importance_mat[i, i:i+48] = tft_vsn_output.detach().cpu()[i, :, feature_idx, 0]\n",
    "\n",
    "ax = sns.lineplot(eval_conti.cpu()[::48, :, feature_idx].squeeze().reshape(-1)[30:], label=r\"Observation of $P_1$\").set(xlabel=\"Time points\")\n",
    "sns.lineplot(np.nanmean(np.where(importance_mat==0.0, np.nan, importance_mat), axis=0)[30:-5], linestyle='--', label=r\"Importance of $P_1$ (InstaTran)\")\n",
    "sns.lineplot(np.nanmean(np.where(tft_importance_mat==0.0, np.nan, tft_importance_mat), axis=0)[30:-5], linestyle=':', label=r\"Importance of $P_1$ (TFT)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti = torch.FloatTensor(eval_a)\n",
    "eval_cate = torch.LongTensor(eval_b)\n",
    "eval_future = torch.LongTensor(eval_c)\n",
    "eval_label = torch.FloatTensor(eval_d)\n",
    "eval_past_label = torch.FloatTensor(eval_e)\n",
    "\n",
    "instatran_output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2  = instatran(eval_conti, eval_cate, eval_future)\n",
    "tft_output = tft(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "mpl_style(dark=False)\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "#%%\n",
    "g = sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 48, ], 0.5, axis=0), label=r\"$k = 1$\")\n",
    "g.set_ylim(0, 0.029)\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Median of attention weights\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 49, ], 0.5, axis=0), label=r\"$k = 2$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 50, ], 0.5, axis=0), label=r\"$k = 3$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 51, ], 0.5, axis=0), label=r\"$k = 4$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 52, ], 0.5, axis=0), label=r\"$k = 5$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 53, ], 0.5, axis=0), label=r\"$k = 6$\")\n",
    "g.axvline(47,  linestyle='--', linewidth=2, color='k')\n",
    "# g.axvline(11,  linestyle=':', linewidth=2, color='k')\n",
    "# g.axvline(23,  linestyle=':', linewidth=2, color='k')\n",
    "# g.axvline(35,  linestyle=':', linewidth=2, color='k')\n",
    "xstart = 24\n",
    "ystart = 0.026\n",
    "g.annotate(\"\",\n",
    "            xy=(xstart, ystart),\n",
    "            xytext=(xstart+12, ystart),\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            arrowprops=dict(color='black', arrowstyle=\"<->\"))\n",
    "g.annotate(\"Half-daily interval\", xy=(xstart-4, ystart+0.002), xytext=(xstart-0.7, ystart+0.002), color='black')\n",
    "g.annotate(\"(12 hours)\", xy=(xstart, ystart+0.0005), xytext=(xstart+2.4, ystart+0.0005), color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 54, :], 0.5, axis=0), label=r\"$k = 7$\")\n",
    "g.set_ylim(0, 0.029)\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Median of attention weights\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 55, :], 0.5, axis=0), label=r\"$k = 8$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 56, :], 0.5, axis=0), label=r\"$k = 9$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 57, :], 0.5, axis=0), label=r\"$k = 10$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 58, :], 0.5, axis=0), label=r\"$k = 11$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 59, :], 0.5, axis=0), label=r\"$k = 12$\")\n",
    "g.axvline(47,  linestyle='--', linewidth=2, color='k')\n",
    "xstart = 28\n",
    "ystart = 0.026\n",
    "g.annotate(\"\",\n",
    "            xy=(xstart, ystart),\n",
    "            xytext=(xstart+12, ystart),\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            arrowprops=dict(color='black', arrowstyle=\"<->\"))\n",
    "g.annotate(\"Half-daily interval\", xy=(xstart-4, ystart+0.002), xytext=(xstart-0.7, ystart+0.002), color='black')\n",
    "g.annotate(\"(12 hours)\", xy=(xstart, ystart+0.0005), xytext=(xstart+2.4, ystart+0.0005), color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_past_prediction_results2(true, preds, past, batch_num=0, dark=False):\n",
    "    \n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    from ing_theme_matplotlib import mpl_style # pip install ing_theme_matplotlib \n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    mpl.rcParams[\"figure.dpi\"] = 100\n",
    "    mpl_style(dark=dark)\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 14\n",
    "    BIGGER_SIZE = 18\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "    if type(preds) == torch.Tensor:    \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        true = true.cpu().numpy()[batch_num, ...]\n",
    "        past = past.cpu().numpy() \n",
    "    \n",
    "    else:\n",
    "        true = true.cpu().numpy()[batch_num, ...]\n",
    "        past = past.cpu().numpy()   \n",
    "    \n",
    "    site1_preds = preds[batch_num, :, 0, :]\n",
    "\n",
    "    site1_past = past[batch_num, :, 0]\n",
    "\n",
    "    df_site1 = pd.DataFrame({\"10%\": site1_preds[:, 0],\n",
    "                            #  \"30%\": site1_preds[:, 1],\n",
    "                            #  \"50%\": site1_preds[:, 2],\n",
    "                            #  \"70%\": site1_preds[:, 3],\n",
    "                             \"90%\": site1_preds[:, 4],\n",
    "                             \"Target\": true[:, 0]}).reset_index().melt(id_vars=['index'])\n",
    "   \n",
    "    df_past_site1 = pd.DataFrame({\"Observed\": site1_past}).reset_index().melt(id_vars=['index'])\n",
    "    df_past_site1['index'] = df_past_site1['index'].map(lambda x: x-48)\n",
    "    df_past_site1 = pd.concat([df_past_site1, pd.DataFrame({\"index\": 0, \"variable\": \"Observed\", \"value\": true[0]})], axis=0)\n",
    "    \n",
    "    df_site1_past_pred = pd.concat([df_site1.loc[df_site1['variable'] == 'Target'], df_past_site1], axis=0)\n",
    "    \n",
    "    \n",
    "    palette = {\n",
    "        # '10%': 'tab:orange',\n",
    "        # '30%': 'tab:olive',\n",
    "        # '50%': 'tab:green',\n",
    "        # '70%': 'tab:blue',\n",
    "        # '90%': 'tab:purple',\n",
    "        'Target': 'white' if dark else 'black',\n",
    "        'Observed': 'tab:gray'\n",
    "    }\n",
    "    fig, ax = plt.subplots()\n",
    "    line = sns.lineplot(ax=ax, x='index', y='value', hue='variable', data=df_site1_past_pred, palette=palette)\n",
    "    conf = ax.fill_between(np.arange(12), df_site1.loc[df_site1['variable'] == '10%', 'value'], df_site1.loc[df_site1['variable'] == '90%', 'value'], color='blue', alpha=0.3, label=r'80% interval')\n",
    "    # sns.move_legend(ax1, \"lower center\", bbox_to_anchor=(.5, 1), ncol=4, title=None, frameon=False)\n",
    "    ax.set(xlim=(-48, true.shape[0]), xlabel='Time points', ylabel='Water Level/1000')\n",
    "    ax.legend(loc = 'upper left')\n",
    "    # ax1.legend([])\n",
    "    # ax_fig = ax1.get_figure()    \n",
    "    # ax_fig.savefig('/Users/chulhongsung/Desktop/lab/working_paper/ts/water_level_forecasting/assets/results/site1_past_pred_{}_{}.jpg'.format(str(),str(batch_num)), bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti = torch.FloatTensor(eval_a[1500:1650])\n",
    "eval_cate = torch.LongTensor(eval_b[1500:1650])\n",
    "eval_future = torch.LongTensor(eval_c[1500:1650])\n",
    "eval_label = torch.FloatTensor(eval_d[1500:1650])\n",
    "eval_past_label = torch.FloatTensor(eval_e[1500:1650])\n",
    "\n",
    "instatran.eval()\n",
    "stt_output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2  = instatran(eval_conti, eval_cate, eval_future)\n",
    "\n",
    "deepar.eval()\n",
    "output_deepar = deepar(eval_conti, eval_cate, eval_future)\n",
    "output_deepar_mu, output_deepar_sigma = output_deepar\n",
    "\n",
    "deepar_output = gaussian_quantile(output_deepar_mu, output_deepar_sigma)\n",
    "\n",
    "tft.eval()\n",
    "tft_output = tft(eval_conti, eval_cate, eval_future)\n",
    "\n",
    "mqrnn.eval()\n",
    "mqrnn_output = mqrnn(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran\n",
    "plot_past_prediction_results2(eval_label, stt_output, eval_past_label, batch_num=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFT\n",
    "plot_past_prediction_results2(eval_label, tft_output, eval_past_label, batch_num=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQRNN\n",
    "plot_past_prediction_results2(eval_label, mqrnn_output, eval_past_label, batch_num=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR\n",
    "plot_past_prediction_results2(eval_label, deepar_output, eval_past_label, batch_num=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti = torch.FloatTensor(eval_a)\n",
    "eval_cate = torch.LongTensor(eval_b)\n",
    "eval_future = torch.LongTensor(eval_c)\n",
    "eval_label = torch.FloatTensor(eval_d)\n",
    "eval_past_label = torch.FloatTensor(eval_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.eval()\n",
    "output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2 = instatran(eval_conti, eval_cate, eval_future)\n",
    "\n",
    "tft.eval()\n",
    "confe_output = tft.confe(eval_conti) # (batch_size, seq_len, num_cv, d_embedding)\n",
    "catfe_output = tft.catfe(eval_cate)  # (batch_size, seq_len, num_cate, d_embedding)\n",
    "obs_feature = torch.cat([confe_output, catfe_output], axis=-2)  # (batch_size, seq_len, num_cv + num_cate, d_embedding)\n",
    "x1, tft_vsn_output  = tft.vsn1(obs_feature) # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InstaTran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "fi1.detach().numpy().squeeze().reshape(-1, 16).mean(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std\n",
    "fi1.detach().numpy().squeeze().reshape(-1, 16).std(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1-quantile\n",
    "np.quantile(fi1.detach().numpy().squeeze().reshape(-1, 16), 0.1, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5-quantile\n",
    "np.quantile(fi1.detach().numpy().squeeze().reshape(-1, 16), 0.5, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9-qunatile\n",
    "np.quantile(fi1.detach().numpy().squeeze().reshape(-1, 16), 0.9, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16).mean(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16).std(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1-quantile\n",
    "np.quantile(tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16), 0.1, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5-quantile\n",
    "np.quantile(tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16), 0.5, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9-quantile\n",
    "np.quantile(tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16), 0.9, axis=0).round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
