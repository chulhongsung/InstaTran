{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.abspath(''))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('')))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('') + '/src'))\n",
    "\n",
    "from utils import *\n",
    "from layers import *\n",
    "from models import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from ing_theme_matplotlib import mpl_style\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train_total = pd.read_csv(\"../data/df_train_total.csv\")\n",
    "df_test_total = pd.read_csv(\"../data/df_test_total.csv\")\n",
    "df_merged = pd.read_csv(\"../data/df_merged.csv\")\n",
    "\n",
    "train_conti_input, train_cate_input, train_future_input, train_label = generate_ts_data(df_train_total, df_merged)\n",
    "test_conti_input, test_cate_input, test_future_input, test_label = generate_ts_data(df_test_total, df_merged)\n",
    "\n",
    "eval_a, eval_b, eval_c, eval_d, eval_e = generate_eval_ts(df_test_total, df_merged, input_seq_len=48, tau=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti = torch.FloatTensor(eval_a)\n",
    "eval_cate = torch.LongTensor(eval_b)\n",
    "eval_future = torch.LongTensor(eval_c)\n",
    "eval_label = torch.FloatTensor(eval_d)\n",
    "eval_past_label = torch.FloatTensor(eval_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft = TemporalFusionTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "                \n",
    "deepar = DeepAR(\n",
    "        d_input=16, \n",
    "        d_embedding=3, \n",
    "        n_embedding=[16, 32, 24], \n",
    "        d_model=30, \n",
    "        num_targets=1, \n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "mqrnn = MQRnn(\n",
    "        d_input=16,\n",
    "        d_embedding=1,\n",
    "        n_embedding=[16, 32, 24],\n",
    "        d_model=5,\n",
    "        tau=12,\n",
    "        num_targets=1,\n",
    "        num_quantiles=5,\n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "\n",
    "adj = torch.tensor([[1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                    [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "                ).float()\n",
    "\n",
    "norm_adj = adj/adj.sum(dim=-1).unsqueeze(-1)\n",
    "norm_adj = norm_adj.to(device)\n",
    "\n",
    "\n",
    "\n",
    "ding = STALSTM(48, 16, 12, 5)\n",
    "\n",
    "deng = HSDSTM(\n",
    "    adj=norm_adj,\n",
    "    input_size=16,\n",
    "    seq_len=48,\n",
    "    num_channels=[16, 16],\n",
    "    node_dim=1,\n",
    "    dropout=0.1,\n",
    "    num_levels=3,\n",
    "    tau=12,\n",
    "    num_quantiles=5\n",
    "    )\n",
    "\n",
    "\n",
    "mqrnn.load_state_dict(torch.load(\"../assets/MQRnn.pth\", map_location=\"cpu\"))\n",
    "deepar.load_state_dict(torch.load(\"../assets/DeepAR.pth\", map_location='cpu'))\n",
    "tft.load_state_dict(torch.load(\"../assets/TFT.pth\", map_location=\"cpu\"))\n",
    "ding.load_state_dict(torch.load('../assets/STALSTM.pth', map_location='cpu'))\n",
    "deng.load_state_dict(torch.load('../assets/HSDSTM.pth',  map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_for_deng, _, _ = generate_eval_ts_for_deng(df_test_total, df_merged)\n",
    "\n",
    "deng.eval()\n",
    "deng_output = deng(torch.tensor(test_input_for_deng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_for_ding, _, _ = generate_eval_ts_for_ding(df_test_total, df_merged)\n",
    "\n",
    "ding.eval()\n",
    "ding_output, alpha, beta = ding(torch.tensor(test_input_for_ding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = torch.tensor([ [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "                ).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran = InstaTran(\n",
    "    d_model=10,\n",
    "    d_embedding=3,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=sps,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "instatran_wo_sps = SpatialTemporalTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=None,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "instatran_parallel = SpatialTemporalParallelTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=None,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "instatran_wo_M_S = SpatialTemporalTransformer2(\n",
    "    d_model=10,\n",
    "    d_embedding=3,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=None,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "\n",
    "instatran_w_tft_decoder = SpatialTemporalTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=sps,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.load_state_dict(torch.load(\"../assets/InstaTran.pth\", map_location='cpu'))\n",
    "instatran_wo_sps.load_state_dict(torch.load(\"../assets/InstaTran_wo_sps.pth\", map_location='cpu'))\n",
    "instatran_parallel.load_state_dict(torch.load(\"../assets/InstaTran_parallel.pth\", map_location='cpu'))\n",
    "instatran_wo_M_S.load_state_dict(torch.load(\"../assets/InstaTran_wo_M_S.pth\", map_location='cpu'))\n",
    "instatran_w_tft_decoder.load_state_dict(torch.load(\"../assets/InstaTran_w_tft_decoder.pth\", map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 60\n",
    "mpl_style(dark=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti_sample = torch.FloatTensor(eval_a[1500:1650])\n",
    "eval_cate_sample = torch.LongTensor(eval_b[1500:1650])\n",
    "eval_future_sample = torch.LongTensor(eval_c[1500:1650])\n",
    "eval_label_sample = torch.FloatTensor(eval_d[1500:1650])\n",
    "eval_past_label_sample = torch.FloatTensor(eval_e[1500:1650])\n",
    "\n",
    "instatran.eval()\n",
    "output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2 = instatran(eval_conti_sample, eval_cate_sample, eval_future_sample)\n",
    "\n",
    "instatran_wo_sps.eval()\n",
    "output_no_sps, ssa_weight1_no_sps, ssa_weight2_no_sps, tsa_weight_no_sps, dec_weights_no_sps, fi1_no_sps, fi2_no_sps = instatran_wo_sps(eval_conti_sample, eval_cate_sample, eval_future_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 4 (a) and (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dry\n",
    "plt.matshow(ssa_weight2[10, 15, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")\n",
    "\n",
    "plt.matshow(ssa_weight2_no_sps[10, 15, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 4 (c) and (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainy\n",
    "plt.matshow(ssa_weight2[50, 0, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")\n",
    "\n",
    "plt.matshow(ssa_weight2_no_sps[50, 0, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft.eval()\n",
    "confe_output = tft.confe(eval_conti_sample) \n",
    "catfe_output = tft.catfe(eval_cate_sample)  \n",
    "obs_feature = torch.cat([confe_output, catfe_output], axis=-2)  \n",
    "x1, tft_vsn_output  = tft.vsn1(obs_feature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.eval()\n",
    "instatran_output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2  = instatran(eval_conti_sample, eval_cate_sample, eval_future_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 5 (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(eval_conti_sample.cpu()[::48, :, 0].squeeze().reshape(-1)[30:], label=r\"Observation of $P_1$\").set(xlabel=\"Time points\")\n",
    "sns.lineplot(fi1.detach().cpu()[::48, :, 0, 0].reshape(-1)[30:], linestyle='--', label=r\"Importance of $P_1$ (InstaTran)\")\n",
    "sns.lineplot(tft_vsn_output.detach().cpu()[::48, :, 0, 0].reshape(-1)[30:], linestyle=':', label=r\"Importance of $P_1$ (TFT)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_idx = 8\n",
    "importance_mat = np.zeros((150, 197))\n",
    "for i in range(150):\n",
    "    importance_mat[i, i:i+48] = fi1.detach().cpu()[i, :, feature_idx, 0]\n",
    "\n",
    "\n",
    "tft_importance_mat = np.zeros((150, 197))\n",
    "for i in range(150):\n",
    "    tft_importance_mat[i, i:i+48] = tft_vsn_output.detach().cpu()[i, :, feature_idx, 0]\n",
    "\n",
    "ax = sns.lineplot(eval_conti_sample.cpu()[::48, :, feature_idx].squeeze().reshape(-1)[30:], label=r\"Observation of OF\").set(xlabel=\"Time points\")\n",
    "sns.lineplot(np.nanmean(np.where(importance_mat==0.0, np.nan, importance_mat), axis=0)[30:-5], linestyle='--', label=r\"Importance of OF (InstaTran)\")\n",
    "sns.lineplot(np.nanmean(np.where(tft_importance_mat==0.0, np.nan, tft_importance_mat), axis=0)[30:-5], linestyle=':', label=r\"Importance of OF (TFT)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conti = torch.FloatTensor(eval_a)\n",
    "eval_cate = torch.LongTensor(eval_b)\n",
    "eval_future = torch.LongTensor(eval_c)\n",
    "eval_label = torch.FloatTensor(eval_d)\n",
    "eval_past_label = torch.FloatTensor(eval_e)\n",
    "\n",
    "instatran_output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2  = instatran(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 6 (a) and (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl_style(dark=False)\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)         \n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     \n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)   \n",
    "plt.rc('xtick', labelsize=MEDIUM_SIZE)  \n",
    "plt.rc('ytick', labelsize=MEDIUM_SIZE)   \n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    \n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  \n",
    "\n",
    "g = sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 48, ], 0.5, axis=0), label=r\"$k = 1$\")\n",
    "g.set_ylim(0, 0.029)\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Median of attention weights\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 49, ], 0.5, axis=0), label=r\"$k = 2$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 50, ], 0.5, axis=0), label=r\"$k = 3$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 51, ], 0.5, axis=0), label=r\"$k = 4$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 52, ], 0.5, axis=0), label=r\"$k = 5$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 53, ], 0.5, axis=0), label=r\"$k = 6$\")\n",
    "g.axvline(47,  linestyle='--', linewidth=2, color='k')\n",
    "\n",
    "xstart = 24\n",
    "ystart = 0.026\n",
    "g.annotate(\"\",\n",
    "            xy=(xstart, ystart),\n",
    "            xytext=(xstart+12, ystart),\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            arrowprops=dict(color='black', arrowstyle=\"<->\"))\n",
    "g.annotate(\"Half-daily interval\", xy=(xstart-4, ystart+0.002), xytext=(xstart-0.7, ystart+0.002), color='black')\n",
    "g.annotate(\"(12 hours)\", xy=(xstart, ystart+0.0005), xytext=(xstart+2.4, ystart+0.0005), color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 54, :], 0.5, axis=0), label=r\"$k = 7$\")\n",
    "g.set_ylim(0, 0.029)\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Median of attention weights\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 55, :], 0.5, axis=0), label=r\"$k = 8$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 56, :], 0.5, axis=0), label=r\"$k = 9$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 57, :], 0.5, axis=0), label=r\"$k = 10$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 58, :], 0.5, axis=0), label=r\"$k = 11$\")\n",
    "sns.lineplot(np.quantile(dec_weights.detach().numpy()[:, 59, :], 0.5, axis=0), label=r\"$k = 12$\")\n",
    "g.axvline(47,  linestyle='--', linewidth=2, color='k')\n",
    "xstart = 28\n",
    "ystart = 0.026\n",
    "g.annotate(\"\",\n",
    "            xy=(xstart, ystart),\n",
    "            xytext=(xstart+12, ystart),\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            arrowprops=dict(color='black', arrowstyle=\"<->\"))\n",
    "g.annotate(\"Half-daily interval\", xy=(xstart-4, ystart+0.002), xytext=(xstart-0.7, ystart+0.002), color='black')\n",
    "g.annotate(\"(12 hours)\", xy=(xstart, ystart+0.0005), xytext=(xstart+2.4, ystart+0.0005), color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 6 (c) and (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m catfe_output \u001b[38;5;241m=\u001b[39m tft\u001b[38;5;241m.\u001b[39mcatfe(eval_cate)  \n\u001b[0;32m      5\u001b[0m obs_feature \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([confe_output, catfe_output], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \n\u001b[1;32m----> 6\u001b[0m x1, _  \u001b[38;5;241m=\u001b[39m \u001b[43mtft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvsn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_feature\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      7\u001b[0m future_embedding \u001b[38;5;241m=\u001b[39m tft\u001b[38;5;241m.\u001b[39mcatfe(eval_future) \n\u001b[0;32m      8\u001b[0m x2, _ \u001b[38;5;241m=\u001b[39m tft\u001b[38;5;241m.\u001b[39mvsn2(future_embedding) \n",
      "File \u001b[1;32mc:\\Users\\hsc93\\anaconda3\\envs\\ijf_rp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\hsc93\\OneDrive\\바탕 화면\\InstaTran\\src\\layers.py:78\u001b[0m, in \u001b[0;36mVariableSelectionNetwork.forward\u001b[1;34m(self, xi)\u001b[0m\n\u001b[0;32m     76\u001b[0m tmp_xi_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxi_grn):\n\u001b[1;32m---> 78\u001b[0m     tmp_xi \u001b[38;5;241m=\u001b[39m \u001b[43ml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     tmp_xi_list\u001b[38;5;241m.\u001b[39mappend(tmp_xi)\n\u001b[0;32m     80\u001b[0m xi_list \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(tmp_xi_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hsc93\\anaconda3\\envs\\ijf_rp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\hsc93\\OneDrive\\바탕 화면\\InstaTran\\src\\layers.py:60\u001b[0m, in \u001b[0;36mGatedResidualNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     59\u001b[0m     eta_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(x))\n\u001b[1;32m---> 60\u001b[0m     eta_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[43m(\u001b[49m\u001b[43meta_2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     grn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgluln(eta_1, eta_2)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grn_output\n",
      "File \u001b[1;32mc:\\Users\\hsc93\\anaconda3\\envs\\ijf_rp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\hsc93\\anaconda3\\envs\\ijf_rp\\lib\\site-packages\\torch\\nn\\modules\\activation.py:517\u001b[0m, in \u001b[0;36mELU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hsc93\\anaconda3\\envs\\ijf_rp\\lib\\site-packages\\torch\\nn\\functional.py:1548\u001b[0m, in \u001b[0;36melu\u001b[1;34m(input, alpha, inplace)\u001b[0m\n\u001b[0;32m   1546\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[0;32m   1547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1548\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tft.eval()\n",
    "confe_output = tft.confe(eval_conti) \n",
    "catfe_output = tft.catfe(eval_cate)  \n",
    "\n",
    "obs_feature = torch.cat([confe_output, catfe_output], axis=-2) \n",
    "x1, _  = tft.vsn1(obs_feature) \n",
    "future_embedding = tft.catfe(eval_future) \n",
    "x2, _ = tft.vsn2(future_embedding) \n",
    "delta, glu_phi, decoder_weights = tft.tfd(x1, x2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 48, ], 0.5, axis=0), label=r\"$k = 1$\")\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Median of Attention Weights\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 49, ], 0.5, axis=0), label=r\"$k = 2$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 50, ], 0.5, axis=0), label=r\"$k = 3$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 51, ], 0.5, axis=0), label=r\"$k = 4$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 52, ], 0.5, axis=0), label=r\"$k = 5$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 53, ], 0.5, axis=0), label=r\"$k = 6$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 54, ], 0.5, axis=0), label=r\"$k = 7$\")\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Median of Attention Weights\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 55, ], 0.5, axis=0), label=r\"$k = 8$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 56, ], 0.5, axis=0), label=r\"$k = 9$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 57, ], 0.5, axis=0), label=r\"$k = 10$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 58, ], 0.5, axis=0), label=r\"$k = 11$\")\n",
    "sns.lineplot(np.quantile(decoder_weights.detach().numpy()[:, 59, ], 0.5, axis=0), label=r\"$k = 12$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure E.10 (a) and (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran_wo_M_S.eval()\n",
    "output_no_sps, ssa_weight1_no_sps, ssa_weight2_no_sps, tsa_weight_no_sps, dec_weights_no_sps, fi1_no_sps, fi2_no_sps = instatran_wo_M_S(eval_conti, eval_cate, eval_future)\n",
    "\n",
    "g = sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 48, ], 0.5, axis=0), label=r\"$k = 1$\")\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Attention weights\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 49, ], 0.5, axis=0), label=r\"$k = 2$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 50, ], 0.5, axis=0), label=r\"$k = 3$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 51, ], 0.5, axis=0), label=r\"$k = 4$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 52, ], 0.5, axis=0), label=r\"$k = 5$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 53, ], 0.5, axis=0), label=r\"$k = 6$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 48, ], 0.5, axis=0), label=r\"$k = 1$\")\n",
    "g.set_ylim(0, 0.029)\n",
    "g.set_xticks([0, 12, 24, 36, 47, 59], [\"-47\", \"-35\", \"-23\", \"-11\", \"0\", \"12\"])\n",
    "g.set_xlabel(\"Time points\")\n",
    "g.set_ylabel(\"Median of attention weights\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 49, ], 0.5, axis=0), label=r\"$k = 2$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 50, ], 0.5, axis=0), label=r\"$k = 3$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 51, ], 0.5, axis=0), label=r\"$k = 4$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 52, ], 0.5, axis=0), label=r\"$k = 5$\")\n",
    "sns.lineplot(np.quantile(dec_weights_no_sps.detach().numpy()[:, 53, ], 0.5, axis=0), label=r\"$k = 6$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_past_prediction_results2(true, preds, past, batch_num=0, dark=False):\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    from ing_theme_matplotlib import mpl_style \n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    mpl.rcParams[\"figure.dpi\"] = 60\n",
    "    mpl_style(dark=dark)\n",
    "    SMALL_SIZE = 10\n",
    "    MEDIUM_SIZE = 14\n",
    "    BIGGER_SIZE = 18\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          \n",
    "    plt.rc('axes', titlesize=MEDIUM_SIZE)     \n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    \n",
    "    plt.rc('xtick', labelsize=MEDIUM_SIZE)   \n",
    "    plt.rc('ytick', labelsize=MEDIUM_SIZE)    \n",
    "    plt.rc('legend', fontsize=MEDIUM_SIZE)    \n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  \n",
    "\n",
    "    if type(preds) == torch.Tensor:    \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        true = true.cpu().numpy()[batch_num, ...]\n",
    "        past = past.cpu().numpy() \n",
    "    \n",
    "    else:\n",
    "        true = true.cpu().numpy()[batch_num, ...]\n",
    "        past = past.cpu().numpy()   \n",
    "    \n",
    "    site1_preds = preds[batch_num, :, 0, :]\n",
    "\n",
    "    site1_past = past[batch_num, :, 0]\n",
    "\n",
    "    df_site1 = pd.DataFrame({\"10%\": site1_preds[:, 0],\n",
    "                             \"90%\": site1_preds[:, 4],\n",
    "                             \"Target\": true[:, 0]}).reset_index().melt(id_vars=['index'])\n",
    "   \n",
    "    df_past_site1 = pd.DataFrame({\"Observed\": site1_past}).reset_index().melt(id_vars=['index'])\n",
    "    df_past_site1['index'] = df_past_site1['index'].map(lambda x: x-48)\n",
    "    df_past_site1 = pd.concat([df_past_site1, pd.DataFrame({\"index\": 0, \"variable\": \"Observed\", \"value\": true[0]})], axis=0)\n",
    "    \n",
    "    df_site1_past_pred = pd.concat([df_site1.loc[df_site1['variable'] == 'Target'], df_past_site1], axis=0)\n",
    "    \n",
    "    \n",
    "    palette = {\n",
    "        'Target': 'white' if dark else 'black',\n",
    "        'Observed': 'tab:gray'\n",
    "    }\n",
    "    fig, ax = plt.subplots()\n",
    "    line = sns.lineplot(ax=ax, x='index', y='value', hue='variable', data=df_site1_past_pred, palette=palette)\n",
    "    conf = ax.fill_between(np.arange(12), df_site1.loc[df_site1['variable'] == '10%', 'value'], df_site1.loc[df_site1['variable'] == '90%', 'value'], color='blue', alpha=0.3, label=r'80% interval')\n",
    "    ax.set(xlim=(-48, true.shape[0]), xlabel='Time points', ylabel='Water Level/1000')\n",
    "    ax.legend(loc = 'upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 7 (a) - (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.eval()\n",
    "stt_output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2  = instatran(eval_conti_sample, eval_cate_sample, eval_future_sample)\n",
    "\n",
    "deepar.eval()\n",
    "output_deepar = deepar(eval_conti_sample, eval_cate_sample, eval_future_sample)\n",
    "output_deepar_mu, output_deepar_sigma = output_deepar\n",
    "\n",
    "deepar_output = gaussian_quantile(output_deepar_mu, output_deepar_sigma)\n",
    "\n",
    "tft.eval()\n",
    "tft_output = tft(eval_conti_sample, eval_cate_sample, eval_future_sample)\n",
    "\n",
    "mqrnn.eval()\n",
    "mqrnn_output = mqrnn(eval_conti_sample, eval_cate_sample, eval_future_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran\n",
    "plot_past_prediction_results2(eval_label_sample, stt_output, eval_past_label_sample, batch_num=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFT\n",
    "plot_past_prediction_results2(eval_label_sample, tft_output, eval_past_label_sample, batch_num=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQRNN\n",
    "plot_past_prediction_results2(eval_label_sample, mqrnn_output, eval_past_label_sample, batch_num=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR\n",
    "plot_past_prediction_results2(eval_label_sample, deepar_output, eval_past_label_sample, batch_num=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure D.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 60\n",
    "plt.matshow(alpha[batch_num, 0:1, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.yticks([])\n",
    "\n",
    "batch_num = 1549\n",
    "plt.matshow(alpha[batch_num, 1:2, :].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtcn_output = deng.levels[0][0](torch.tensor(test_input_for_deng))\n",
    "\n",
    "Wh = torch.matmul(gtcn_output, deng.levels[0][1].gat.W)\n",
    "e = deng.levels[0][1].gat._prepare_attentional_mechanism_input(Wh)\n",
    "zero_vec = -9e15*torch.ones_like(e)\n",
    "attention = torch.where(deng.adj > 0, e, zero_vec)\n",
    "alpha_ = F.softmax(attention, dim=-1)\n",
    "\n",
    "\n",
    "# Dry\n",
    "batch_num = 60\n",
    "time_step = 0\n",
    "plt.matshow(alpha_[batch_num, time_step, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")\n",
    "\n",
    "# Rainy\n",
    "batch_num = 1549\n",
    "time_step = 1\n",
    "plt.matshow(alpha_[batch_num, time_step, ...].detach().numpy(), cmap='Reds')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Variable index\")\n",
    "plt.ylabel(\"Variable index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.eval()\n",
    "instatran_wo_M_S.eval()\n",
    "instatran_parallel.eval()\n",
    "instatran_w_tft_decoder.eval()\n",
    "\n",
    "instatran_output, _, _, _, _, _, _  = instatran(eval_conti, eval_cate, eval_future)\n",
    "wo_M_S_output, _, _, _, _, _, _  = instatran_wo_M_S(eval_conti, eval_cate, eval_future)\n",
    "parallel_output, _, _, _, _, _, _  = instatran_parallel(eval_conti, eval_cate, eval_future)\n",
    "tft_decoder_output, _, _, _, _, _, _  = instatran_w_tft_decoder(eval_conti, eval_cate, eval_future)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran QLs\n",
    "print(torch.maximum(0.9 * (eval_label.squeeze() - instatran_output[..., 4].squeeze()), (1-0.9)*(instatran_output[..., 4].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.7 * (eval_label.squeeze() - instatran_output[..., 3].squeeze()), (1-0.7)*(instatran_output[..., 3].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.5 * (eval_label.squeeze() - instatran_output[..., 2].squeeze()), (1-0.5)*(instatran_output[..., 2].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran without M_S QLs \n",
    "print(torch.maximum(0.9 * (eval_label.squeeze() - wo_M_S_output[..., 4].squeeze()), (1-0.9)*(wo_M_S_output[..., 4].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.7 * (eval_label.squeeze() - wo_M_S_output[..., 3].squeeze()), (1-0.7)*(wo_M_S_output[..., 3].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.5 * (eval_label.squeeze() - wo_M_S_output[..., 2].squeeze()), (1-0.5)*(wo_M_S_output[..., 2].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran without M_S q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < wo_M_S_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < wo_M_S_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < wo_M_S_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < wo_M_S_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < wo_M_S_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < wo_M_S_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran parallel attention QLs\n",
    "print(torch.maximum(0.9 * (eval_label.squeeze() - parallel_output[..., 4].squeeze()), (1-0.9)*(parallel_output[..., 4].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.7 * (eval_label.squeeze() - parallel_output[..., 3].squeeze()), (1-0.7)*(parallel_output[..., 3].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.5 * (eval_label.squeeze() - parallel_output[..., 2].squeeze()), (1-0.5)*(parallel_output[..., 2].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran parallel attention q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < parallel_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < parallel_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < parallel_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < parallel_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < parallel_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < parallel_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran with TFT decoder QLs\n",
    "print(torch.maximum(0.9 * (eval_label.squeeze() - tft_decoder_output[..., 4].squeeze()), (1-0.9)*(tft_decoder_output[..., 4].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.7 * (eval_label.squeeze() - tft_decoder_output[..., 3].squeeze()), (1-0.7)*(tft_decoder_output[..., 3].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.5 * (eval_label.squeeze() - tft_decoder_output[..., 2].squeeze()), (1-0.5)*(tft_decoder_output[..., 2].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran with TFT decoder q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < tft_decoder_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < tft_decoder_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < tft_decoder_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < tft_decoder_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < tft_decoder_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < tft_decoder_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instatran.eval()\n",
    "output, ssa_weight1, ssa_weight2, tsa_weight, dec_weights, fi1, fi2 = instatran(eval_conti, eval_cate, eval_future)\n",
    "\n",
    "tft.eval()\n",
    "confe_output = tft.confe(eval_conti) \n",
    "catfe_output = tft.catfe(eval_cate)  \n",
    "obs_feature = torch.cat([confe_output, catfe_output], axis=-2)  \n",
    "x1, tft_vsn_output  = tft.vsn1(obs_feature) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3 - InstaTran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "fi1.detach().numpy().squeeze().reshape(-1, 16).mean(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std\n",
    "fi1.detach().numpy().squeeze().reshape(-1, 16).std(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1-quantile\n",
    "np.quantile(fi1.detach().numpy().squeeze().reshape(-1, 16), 0.1, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5-quantile\n",
    "np.quantile(fi1.detach().numpy().squeeze().reshape(-1, 16), 0.5, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9-qunatile\n",
    "np.quantile(fi1.detach().numpy().squeeze().reshape(-1, 16), 0.9, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 3 - TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean\n",
    "tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16).mean(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std\n",
    "tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16).std(axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1-quantile\n",
    "np.quantile(tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16), 0.1, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5-quantile\n",
    "np.quantile(tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16), 0.5, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9-quantile\n",
    "np.quantile(tft_vsn_output.detach().numpy().squeeze()[..., :16].reshape(-1, 16), 0.9, axis=0).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 5 - Deep learning based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepar.eval()\n",
    "output_deepar = deepar(eval_conti, eval_cate, eval_future)\n",
    "output_deepar_mu, output_deepar_sigma = output_deepar\n",
    "output_deepar_mu.detach().cpu().numpy()\n",
    "output_deepar_mu.shape\n",
    "deepar_output = gaussian_quantile(output_deepar_mu, output_deepar_sigma)\n",
    "\n",
    "mqrnn.eval()\n",
    "mqrnn_output = mqrnn(eval_conti, eval_cate, eval_future)\n",
    "\n",
    "tft.eval()\n",
    "tft_output = tft(eval_conti, eval_cate, eval_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran QLs\n",
    "print(torch.maximum(0.9 * (eval_label.squeeze() - instatran_output[..., 4].squeeze()), (1-0.9)*(instatran_output[..., 4].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.7 * (eval_label.squeeze() - instatran_output[..., 3].squeeze()), (1-0.7)*(instatran_output[..., 3].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "      torch.maximum(0.5 * (eval_label.squeeze() - instatran_output[..., 2].squeeze()), (1-0.5)*(instatran_output[..., 2].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstaTran q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < instatran_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR QLs\n",
    "print(\n",
    "    torch.maximum(0.9 * (eval_label.squeeze() - torch.Tensor(deepar_output)[..., 4].squeeze()), (1-0.9)*(torch.Tensor(deepar_output)[..., 4].squeeze() - eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.7 * (eval_label.squeeze() - torch.Tensor(deepar_output)[..., 3].squeeze()), (1-0.7)*(torch.Tensor(deepar_output)[..., 3].squeeze() - eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.5 * (eval_label.squeeze() - torch.Tensor(deepar_output)[..., 2].squeeze()), (1-0.5)*(torch.Tensor(deepar_output)[..., 2].squeeze() - eval_label.squeeze() )).mean().detach().numpy().round(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < torch.Tensor(deepar_output)[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < torch.Tensor(deepar_output)[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < torch.Tensor(deepar_output)[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < torch.Tensor(deepar_output)[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < torch.Tensor(deepar_output)[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < torch.Tensor(deepar_output)[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQRnn QLs\n",
    "print(\n",
    "    torch.maximum(0.9 * (eval_label.squeeze() - mqrnn_output[..., 4].squeeze()), (1-0.9)*(mqrnn_output[..., 4].squeeze() -eval_label.squeeze())).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.7 * (eval_label.squeeze() - mqrnn_output[..., 3].squeeze()), (1-0.7)*(mqrnn_output[..., 3].squeeze() -eval_label.squeeze())).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.5 * (eval_label.squeeze() - mqrnn_output[..., 2].squeeze()), (1-0.5)*(mqrnn_output[..., 2].squeeze() -eval_label.squeeze())).mean().detach().numpy().round(4),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MQRnn q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < mqrnn_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < mqrnn_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < mqrnn_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < mqrnn_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < mqrnn_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < mqrnn_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFT QLs\n",
    "print(\n",
    "    torch.maximum(0.9 * (eval_label.squeeze() - tft_output[..., 4].squeeze()), (1-0.9)*(tft_output[..., 4].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.7 * (eval_label.squeeze() - tft_output[..., 3].squeeze()), (1-0.7)*(tft_output[..., 3].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4), \n",
    "    torch.maximum(0.5 * (eval_label.squeeze() - tft_output[..., 2].squeeze()), (1-0.5)*(tft_output[..., 2].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFT q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < tft_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < tft_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < tft_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < tft_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < tft_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < tft_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSDSTM QLs\n",
    "print(\n",
    "    torch.maximum(0.9 * (eval_label.squeeze() - deng_output[..., 4].squeeze()), (1-0.9)*(deng_output[..., 4].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.7 * (eval_label.squeeze() - deng_output[..., 3].squeeze()), (1-0.7)*(deng_output[..., 3].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.5 * (eval_label.squeeze() - deng_output[..., 2].squeeze()), (1-0.5)*(deng_output[..., 2].squeeze() -eval_label.squeeze() )).mean().detach().numpy().round(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSDSTM q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < deng_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < deng_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < deng_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < deng_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < deng_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < deng_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STA-LSTM QLs\n",
    "print(\n",
    "    torch.maximum(0.9 * (torch.tensor(eval_label).squeeze() - ding_output[..., 4].squeeze()), (1-0.9)*(ding_output[..., 4].squeeze() -torch.tensor(eval_label).squeeze() )).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.7 * (torch.tensor(eval_label).squeeze() - ding_output[..., 3].squeeze()), (1-0.7)*(ding_output[..., 3].squeeze() -torch.tensor(eval_label).squeeze() )).mean().detach().numpy().round(4),\n",
    "    torch.maximum(0.5 * (torch.tensor(eval_label).squeeze() - ding_output[..., 2].squeeze()), (1-0.5)*(ding_output[..., 2].squeeze() -torch.tensor(eval_label).squeeze() )).mean().detach().numpy().round(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STA-LSTM q-Rates, |q - q-Rate|\n",
    "print(np.mean(eval_label.squeeze().detach().numpy() < ding_output[..., 4].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.9 - np.mean(eval_label.squeeze().detach().numpy() < ding_output[..., 4].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < ding_output[..., 3].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.7 - np.mean(eval_label.squeeze().detach().numpy() < ding_output[..., 3].squeeze().detach().numpy())).round(3),\n",
    "      np.mean(eval_label.squeeze().detach().numpy() < ding_output[..., 2].squeeze().detach().numpy()).round(3), \n",
    "      np.abs(0.5 - np.mean(eval_label.squeeze().detach().numpy() < ding_output[..., 2].squeeze().detach().numpy())).round(3),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ijf_rp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
