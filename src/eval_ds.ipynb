{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.abspath(''))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('')))\n",
    "sys.path.append(os.path.abspath(os.path.abspath('') + '/src'))\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "from utils import *\n",
    "from layers import *\n",
    "from models import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from ing_theme_matplotlib import mpl_style # pip install ing_theme_matplotlib \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 200\n",
    "mpl_style(dark=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ts/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "ding = STALSTM(48, 16, 12, 5)\n",
    "\n",
    "adj = torch.tensor([[1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                    [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "        ).float()\n",
    "\n",
    "norm_adj = adj/adj.sum(dim=-1).unsqueeze(-1)\n",
    "deng = HSDSTM(adj=norm_adj,                  \n",
    "                input_size=16,\n",
    "                seq_len=48,\n",
    "                num_channels=[16, 16],\n",
    "                node_dim=1,\n",
    "                dropout=0.1,\n",
    "                num_levels=3,\n",
    "                tau=12,\n",
    "                num_quantiles=5)\n",
    "\n",
    "\n",
    "deepar = DeepAR(\n",
    "        d_input=16, \n",
    "        d_embedding=3, \n",
    "        n_embedding=[16, 32, 24], \n",
    "        d_model=30, \n",
    "        num_targets=1, \n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "mqrnn = MQRnn(\n",
    "        d_input=16,\n",
    "        d_embedding=1,\n",
    "        n_embedding=[16, 32, 24],\n",
    "        d_model=5,\n",
    "        tau=12,\n",
    "        num_targets=1,\n",
    "        num_quantiles=5,\n",
    "        n_layers=3,\n",
    "        dr=0.1\n",
    "    )\n",
    "\n",
    "quanilte_levels = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "tft = TemporalFusionTransformer(\n",
    "    d_model=30,\n",
    "    d_embedding=5,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=quanilte_levels,\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "sps = torch.tensor([ [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
    "                ).float()\n",
    "\n",
    "instatran = InstaTran(\n",
    "    d_model=20,\n",
    "    d_embedding=3,\n",
    "    cate_dims=[16, 32, 24],\n",
    "    spatial_structure=sps,\n",
    "    num_cv=16,\n",
    "    seq_len=48,\n",
    "    num_targets=1,\n",
    "    tau=12,\n",
    "    quantile=quanilte_levels,\n",
    "    dr=0.1,\n",
    "    device=device\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2016\"\n",
    "deepar.load_state_dict(torch.load('../assets/ds/ds_DeepAR_{}_best.pth'.format(year), map_location='cpu'))\n",
    "mqrnn.load_state_dict(torch.load('../assets/ds/ds_MQRnn_{}_best.pth'.format(year), map_location='cpu'))\n",
    "tft.load_state_dict(torch.load('../assets/ds/ds_TFT_{}_best.pth'.format(year), map_location='cpu'))\n",
    "ding.load_state_dict(torch.load('../assets/ds/ds_STALSTM_{}_best.pth'.format(year), map_location='cpu'))\n",
    "deng.load_state_dict(torch.load('../assets/ds/ds_HSDSTM_{}_best.pth'.format(year), map_location='cpu'))\n",
    "instatran.load_state_dict(torch.load('../assets/ds/ds_InstaTran_{}_best.pth'.format(year), map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0078, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "0.9222689075630253\n",
      "-0.022268907563025242\n",
      "tensor(0.0184, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "0.8512488328664799\n",
      "-0.15124883286647994\n",
      "tensor(0.0264, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "0.7641223155929038\n",
      "-0.2641223155929038\n"
     ]
    }
   ],
   "source": [
    "# for year in [\"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"]:\n",
    "df_test_total = pd.read_csv(\"../data/df_test_total_ds_{}.csv\".format(year))\n",
    "df_merged = pd.read_csv(\"../data/df_merged_ds_{}.csv\".format(year))\n",
    "\n",
    "test_input, eval_label = generate_ts_data_for_deng(df_test_total, df_merged)\n",
    "deng.eval()\n",
    "eval_label = torch.tensor(eval_label)\n",
    "deng_output = deng(torch.tensor(test_input))\n",
    "\n",
    "print(torch.maximum(0.9 * (eval_label.squeeze() - deng_output[..., 4].squeeze()), (1-0.9)*(deng_output[..., 4].squeeze() -eval_label.squeeze() )).mean())\n",
    "print(np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 4].squeeze().detach().cpu().numpy()))\n",
    "print(0.9 - np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 4].squeeze().detach().cpu().numpy()))\n",
    "\n",
    "print(torch.maximum(0.7 * (eval_label.squeeze() - deng_output[..., 3].squeeze()), (1-0.7)*(deng_output[..., 3].squeeze() -eval_label.squeeze() )).mean())\n",
    "print(np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 3].squeeze().detach().cpu().numpy()))\n",
    "print(0.7 - np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 3].squeeze().detach().cpu().numpy()))\n",
    "\n",
    "print(torch.maximum(0.5 * (eval_label.squeeze() - deng_output[..., 2].squeeze()), (1-0.5)*(deng_output[..., 2].squeeze() -eval_label.squeeze() )).mean())\n",
    "print(np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 2].squeeze().detach().cpu().numpy()))\n",
    "print(0.5 - np.mean(eval_label.squeeze().cpu().numpy() < deng_output[..., 2].squeeze().detach().cpu().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
