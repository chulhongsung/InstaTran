{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from sktime.forecasting.arima import ARIMA, AutoARIMA\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning, ValueWarning\n",
    "warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "warnings.simplefilter('ignore', ValueWarning)\n",
    "\n",
    "\n",
    "os.chdir(os.path.abspath(''))\n",
    "df_train_total = pd.read_csv(\"../data/df_train_total.csv\")\n",
    "df_test_total = pd.read_csv(\"../data/df_test_total.csv\")\n",
    "df_merged = pd.read_csv(\"../data/df_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_arima(label_df, input_seq_len=48, tau=12):\n",
    "    col_labels =  'wl_1018680' # ['wl_1018662', 'wl_1018680', 'wl_1018683', 'wl_1019630']\n",
    "    \n",
    "    tmp_df = np.array(label_df.loc[label_df['month'].isin([2,3]), col_labels])\n",
    "    \n",
    "    n = tmp_df.shape[0] - input_seq_len - tau \n",
    "    \n",
    "    conti_input = np.zeros((n, input_seq_len), dtype=np.float32)\n",
    "    label = np.zeros((n, tau))\n",
    "\n",
    "    for j in range(n):\n",
    "        conti_input[j, :] = tmp_df[j:(j+input_seq_len)]\n",
    "        label[j, :] = tmp_df[(j+input_seq_len):(j+input_seq_len+tau)]\n",
    "\n",
    "    return conti_input, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2016\"\n",
    "\n",
    "df_train_total = pd.read_csv(\"../data/df_train_total_ds_{}.csv\".format(year))\n",
    "df_test_total = pd.read_csv(\"../data/df_test_total_ds_{}.csv\".format(year))\n",
    "df_merged = pd.read_csv(\"../data/df_merged_ds_{}.csv\".format(year))\n",
    "\n",
    "fh = ForecastingHorizon(np.arange(1, 13), is_relative=True)\n",
    "\n",
    "arima_forecaster = ARIMA()\n",
    "\n",
    "arima_results = []\n",
    "\n",
    "y_train = df_merged.loc[df_merged[\"month\"].isin([0, 1]), \"wl_1018680\"]\n",
    "arima_forecaster.fit(y_train)\n",
    "\n",
    "y_input, label = generate_ds_arima(df_merged)\n",
    "\n",
    "for i in range(y_input.shape[0]):\n",
    "    arima_forecaster.update(y_input[i], update_params=False)\n",
    "    tmp_result = arima_forecaster.predict_quantiles(fh=fh, alpha=[0.1, 0.5, 0.7, 0.9])\n",
    "    \n",
    "    arima_results.append(tmp_result.values[np.newaxis, ...])\n",
    "\n",
    "arima_results = np.concatenate(arima_results, axis=0)\n",
    "\n",
    "print(np.maximum(0.9 * (label - arima_results[..., 3]), (1-0.9)*(arima_results[..., 3] -label )).mean()/1000) # 0.0031\n",
    "print(np.mean(label < arima_results[..., 3]), 0.9 - np.mean(label < arima_results[..., 3]))  ### 0.638\n",
    "\n",
    "print(np.maximum(0.7 * (label - arima_results[..., 2]), (1-0.7)*(arima_results[..., 2] -label )).mean()/1000) # 0.0051\n",
    "print(np.mean(label < arima_results[..., 2]), 0.7 - np.mean(label < arima_results[..., 2])) ### 0.640\n",
    "\n",
    "print(np.maximum(0.5 * (label - arima_results[..., 1]), (1-0.5)*(arima_results[..., 1] -label )).mean()/1000)  # 0.0059\n",
    "print(np.mean(label < arima_results[..., 1]), 0.5- np.mean(label < arima_results[..., 1])) ### 0.894"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ets_results = []\n",
    "ets_forecaster = AutoETS(auto=True, n_jobs=-1)  \n",
    "\n",
    "ets_forecaster.fit(y_train)\n",
    "\n",
    "for i in range(y_input.shape[0]):\n",
    "    ets_forecaster.update(y_input[i], update_params=False)\n",
    "    tmp_result = ets_forecaster.predict_quantiles(fh=fh, alpha=[0.1, 0.5, 0.7, 0.9])\n",
    "    \n",
    "    ets_results.append(tmp_result.values[np.newaxis, ...])\n",
    "    \n",
    "ets_results = np.concatenate(ets_results, axis=0)\n",
    "\n",
    "print(np.maximum(0.9 * (label - ets_results[..., 3]), (1-0.9)*(ets_results[..., 3] -label )).mean()/1000) \n",
    "print(np.mean(label < ets_results[..., 3]), 0.9 - np.mean(label < ets_results[..., 3])) \n",
    "\n",
    "print(np.maximum(0.7 * (label - ets_results[..., 2]), (1-0.7)*(ets_results[..., 2] -label )).mean()/1000) \n",
    "print(np.mean(label < ets_results[..., 2]), 0.7 - np.mean(label < ets_results[..., 2])) \n",
    "\n",
    "print(np.maximum(0.5 * (label - ets_results[..., 1]), (1-0.5)*(ets_results[..., 1] -label )).mean()/1000)  \n",
    "print(np.mean(label < ets_results[..., 1]), 0.5- np.mean(label < ets_results[..., 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_results = []\n",
    "theta_forecaster = ThetaForecaster()    \n",
    "\n",
    "theta_forecaster.fit(y_train)\n",
    "\n",
    "for i in range(y_input.shape[0]):\n",
    "    theta_forecaster.update(y_input[i], update_params=False)\n",
    "    tmp_result = theta_forecaster.predict_quantiles(fh=fh, alpha=[0.1, 0.5, 0.7, 0.9])\n",
    "    \n",
    "    theta_results.append(tmp_result.values[np.newaxis, ...])\n",
    "\n",
    "theta_results = np.concatenate(theta_results, axis=0)\n",
    "\n",
    "print(np.maximum(0.9 * (label - theta_results[..., 3]), (1-0.9)*(theta_results[..., 3] -label )).mean()/1000)\n",
    "print(np.mean(label < theta_results[..., 3]), 0.9 - np.mean(label < theta_results[..., 3]))  \n",
    "\n",
    "print(np.maximum(0.7 * (label - theta_results[..., 2]), (1-0.7)*(theta_results[..., 2] -label )).mean()/1000) \n",
    "print(np.mean(label < theta_results[..., 2]), 0.7 - np.mean(label < theta_results[..., 2]))\n",
    "\n",
    "print(np.maximum(0.5 * (label - theta_results[..., 1]), (1-0.5)*(theta_results[..., 1] -label )).mean()/1000) \n",
    "print(np.mean(label < theta_results[..., 1]), 0.5- np.mean(label < theta_results[..., 1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "def generate_ts_data_train_for_lgb(label_df, term_list, input_seq_len=48, tau=12):\n",
    "    conti_input_list = []\n",
    "    label_list = []\n",
    "    col_labels =  ['wl_1018680'] \n",
    "\n",
    "    for i in label_df['year'].unique():\n",
    "        tmp_df = np.array(label_df.loc[label_df['month'].isin([0, 1]), :])\n",
    "        tmp_label_df = np.array(label_df.loc[label_df['month'].isin([0, 1]), col_labels])        \n",
    "        n = tmp_df.shape[0] - input_seq_len - tau \n",
    "        covariate = np.zeros((n, input_seq_len, tmp_df.shape[1] - 4 ))   \n",
    "        label = np.zeros((n, tau, len(col_labels)))\n",
    "        \n",
    "        for j in range(n):\n",
    "            covariate[j, :, :] = tmp_df[j:(j+input_seq_len), 4:]\n",
    "            label[j, :, :] = tmp_label_df[(j+input_seq_len):(j+input_seq_len+tau), :]/1000\n",
    "\n",
    "        conti_input_list.append(covariate)\n",
    "        label_list.append(label)\n",
    "    \n",
    "    total_conti_input = np.concatenate(conti_input_list, axis=0)\n",
    "    total_label = np.concatenate(label_list, axis=0)\n",
    "    \n",
    "    return total_conti_input.reshape(-1, total_conti_input.shape[1] * total_conti_input.shape[2]), np.squeeze(total_label)\n",
    "\n",
    "def generate_ts_data_test_for_lgb(label_df, term_list, input_seq_len=48, tau=12):\n",
    "    conti_input_list = []\n",
    "    label_list = []\n",
    "    col_labels =  ['wl_1018680'] \n",
    "    \n",
    "    for i in label_df['year'].unique():\n",
    "        tmp_df = np.array(label_df.loc[label_df['month'].isin([2, 3]), :])\n",
    "        tmp_label_df = np.array(label_df.loc[label_df['month'].isin([2, 3]), col_labels])\n",
    "        n = tmp_df.shape[0] - input_seq_len - tau \n",
    "    \n",
    "        covariate = np.zeros((n, input_seq_len, tmp_df.shape[1] - 4 ))     \n",
    "        label = np.zeros((n, tau, len(col_labels)))\n",
    "\n",
    "        for j in range(n):\n",
    "            covariate[j, :, :] = tmp_df[j:(j+input_seq_len), 4:]\n",
    "            label[j, :, :] = tmp_label_df[(j+input_seq_len):(j+input_seq_len+tau), :]/1000\n",
    "\n",
    "        conti_input_list.append(covariate)\n",
    "        label_list.append(label)\n",
    "    \n",
    "    total_conti_input = np.concatenate(conti_input_list, axis=0)\n",
    "    total_label = np.concatenate(label_list, axis=0)\n",
    "    \n",
    "    return total_conti_input.reshape(-1, total_conti_input.shape[1] * total_conti_input.shape[2]), np.squeeze(total_label) # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = \"2016\"\n",
    "\n",
    "from sktime.transformations.series.fourier import FourierFeatures\n",
    "\n",
    "df_train_total = pd.read_csv(\"../data/df_train_total_ds_{}.csv\".format(year))\n",
    "df_test_total = pd.read_csv(\"../data/df_test_total_ds_{}.csv\".format(year))\n",
    "df_merged = pd.read_csv(\"../data/df_merged_ds_{}.csv\".format(year))\n",
    "\n",
    "term_list = 4\n",
    "transformer = FourierFeatures(sp_list=[24], fourier_terms_list=[term_list])\n",
    "\n",
    "df_merged_lgb = pd.concat([df_merged, transformer.fit_transform(df_merged[[\"wl_1018680\"]])], axis=1)\n",
    "train_input_lgb, label_lgb = generate_ts_data_train_for_lgb(df_merged_lgb, term_list)\n",
    "train_input_lgb.shape\n",
    "label_lgb.shape\n",
    "\n",
    "alphas = [0.5, 0.7, 0.9]\n",
    "\n",
    "model_list = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    params = {\n",
    "        \"objective\": \"quantile\",\n",
    "        \"alpha\": alpha,\n",
    "        \"boosting\": \"gbdt\",\n",
    "\n",
    "    }\n",
    "    gbm = lgb.LGBMRegressor(**params)\n",
    "    regr_multiglb = MultiOutputRegressor(gbm)\n",
    "    regr_multiglb.fit(train_input_lgb, label_lgb)\n",
    "    \n",
    "    model_list.append(\n",
    "        regr_multiglb\n",
    "    )\n",
    "\n",
    "test_input_lgb, test_label_lgb = generate_ts_data_test_for_lgb(df_merged_lgb, term_list)\n",
    "test_input_lgb.shape\n",
    "\n",
    "lgb_results_05 = model_list[0].predict(test_input_lgb)\n",
    "lgb_results_07 = model_list[1].predict(test_input_lgb)\n",
    "lgb_results_09 = model_list[2].predict(test_input_lgb)\n",
    "\n",
    "print(round(np.maximum(0.9 * (test_label_lgb - lgb_results_09), (1-0.9)*(lgb_results_09 -test_label_lgb )).mean(), 4)) # 0.0031\n",
    "print(round(np.mean(test_label_lgb < lgb_results_09), 4), round(0.9 - np.mean(test_label_lgb < lgb_results_09),4))  ### 0.638\n",
    "\n",
    "print(round(np.maximum(0.7 * (test_label_lgb - lgb_results_07), (1-0.7)*(lgb_results_07 -test_label_lgb )).mean(), 4)) # 0.0051\n",
    "print(round(np.mean(test_label_lgb < lgb_results_07),4), round(0.7 - np.mean(test_label_lgb < lgb_results_07), 4)) ### 0.640\n",
    "\n",
    "print(round(np.maximum(0.5 * (test_label_lgb - lgb_results_05), (1-0.5)*(lgb_results_05 -test_label_lgb )).mean(), 4))   # 0.0059\n",
    "print(round(np.mean(test_label_lgb < lgb_results_05), 4), round(0.5- np.mean(test_label_lgb < lgb_results_05),4)) ### 0.894"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
